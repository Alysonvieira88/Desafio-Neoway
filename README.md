<h1 align="center">Desafio de Busca CEP no Site dos Correios</h1>

<p align="center">Sauda√ß√µes viajantes!!</br> Neste projeto iremos nos aventurar em um desafio nunca feito por mim sobre uma busca de dados usando Web Scraping em Python no Site dos correios. O objetivo do projeto √© buscar o maximo de Unidades Federativas e suas faixas de CEPüöÄ.</p>
</br>
</br>
<h2 align="center">üî® Constru√ß√£o do projeto üî®</h2>

<p align="center">Confeso que no projeto eu desafiei meus conhecimentos com algo totalmente do zero e nunca visto por mim, achei imprecionante a quantidade de informa√ß√µes e c√≥digos que podem ser feitos com o famoso Web Scraping.</br></br>Foram longas 22 horas desenvolvendo e buscando informa√ß√µes para a melhor forma de entregar o produto. Inicialmente eu comprei um curso na Udemy de 12 horas sobre Web Scraping em Python onde gerou um <a href="https://www.udemy.com/certificate/UC-f508f580-298c-469b-87f6-dd7c467fb6d6/">certificado</a> ao concluir o curso, al√©m disso passei por muitas pesquisas no google e examina√ß√£o de c√≥digos em HTML. Mostrarei a seguir passo a passo do que foi feito</p>
</br>

<h3 align="center">‚öíÔ∏è BUILTWITH ‚öíÔ∏è</h3>
	   
<p align="center">Bom, o meu primeiro passo foi instalar a biblioteca "builtwith" para verificar as tecnologias utilizadas no site dos correios, ele analisa a URL informada e em seguida retornar√° todas as tecnologias utilizadas pelo site. Instalei a biblioteca utilizando um comando pelo prompt de comando ("pip install builtwith") e importei para o Python utilizando o ("import builtwith"), ap√≥s isso eu utilizei o m√©todo paps("builtwith.parse('http://www.buscacep.correios.com.br/sistemas/buscacep/buscaFaixaCep.cfm')") onde ele traz as tecnologias.</p>
</br>

<h3 align="center">‚öíÔ∏è PYTHON WHOIS ‚öíÔ∏è</h3>
	   
<p align="center">Meu segundo passo foi utilizar a biblioteca Python Whois que serve para identifica√ß√£o de propriedades do site. Instalei tamb√©m pelo prompt utilizando o comando ("pip instal python-whois") e importei tamb√©m utilizando o prompt de comando("import whois") e imprimi o resultado dentro do python utilizando o comando (whois.whois(‚Äòbuscacep.correios.com.br/sistemas/buscacep/buscaFaixaCep.cfm')</p>
</br>

<h3 align="center">‚öíÔ∏è URLLIB E BEAUTIFULSOUP‚öíÔ∏è</h3>
	   
<p align="center">Urllib √© uma biblioteca padr√£o do python e contem fun√ß√µes para solicita√ß√£o de dados web e manipula√ß√£o de cookies. Dentro dessa biblioteca eu utilizei a fun√ß√£o ("urlopen") que serve para ler um objeto remoto por meio de uma rede e ler esse objeto. Esse objeto pode ser arquivos HTML, arquivos de imagens ou qualquer outro fluxo de arquivos. Importei para o Python utilizando ("from urllib.request import urlopen")e abri as informa√ß√µes do site com("urlopen("https://buscacepinter.correios.com.br/app/faixa_cep_uf_localidade/index.php")"), em seguida utilizei a biblioteca BeauifulSoup que n√£o √© padr√£o do Python e √© utilizada para buscar informa√ß√µes em uma p√°gina HTML. Baixei ela manualmente no site ("https://www.crummy.com/software/BeautifulSoup/bs4/download/4.9/beautifulsoup4-4.9.0.tar.gz") e instalei pelo prompt de comando utilizando o ("pip install beautifulsoup4"), importei ela dentro do Python utilizando ("from bs4 import BeautifulSoup"), peguei o conte√∫do do site e armazenei em uma vari√°vel utilizando o ("BeautifulSoup(COLOQUE_AQUI_A_VARIAVEL, "COLOQUE_AQUI_A_VARIAVEL.parser")") e em seguida coloquei alguns parametros a serem seguidos. </p>
</br>
</br>

<h2 align="center">üî® DESENVOLVIMENTO DO PROJETO üî®</h2>

<p align="center">Nessa parte eu explicarei como foi meu racioc√≠nio e os caminhos que eu percorri.</br>Iniciei o c√≥digo inserindo todas as bibliotecas que eu iria utilizar onde que se encontram a cima, em seguida utilizei algumas fun√ß√µes do Urllib e BeautifulSoup para puxar algumas informa√ß√µes, tive algumas dificuldades com o site at√© que encontrei um caminho pelo "Inspecionar" na parte "Sources" onde mostrava como o JavaScript da p√°gina funcionava, percebi que dentro de uma tag possuia algumas informa√ß√µes que poderiam carregar a forma de buscar o CEP na pagina, e o que eu encontrei foi a seguinte informa√ß√£o "carrega-faixa-cep-uf.php", foi ent√£o onde eu modifiquei a URL da pagina acrescentando o que foi encontrado e ficou da seguinte maneira "https://buscacepinter.correios.com.br/app/faixa_cep_uf_localidade/carrega-faixa-cep-uf-localidade.php" e eu acrescentei umas fun√ß√µes para puxar apenas os dados de cada UF, utilizando "?uf=" no final do link, onde depois do "=" receberia a UF desejada. Foi ai que voltei para o c√≥digo e fiz algumas altera√ß√µes, coloquei uma fun√ß√£o do BeautifulSoup para puxar apenas o texto das UFs na p√°gina "http://www.buscacep.correios.com.br/sistemas/buscacep/resultadoBuscaFaixaCEP.cfm", em seguida criei um loop na fun√ß√£o utilizada anteriormente e armazenando a informa√ß√£o em outro objeto, mandei imprimir essa objeto e em seguida transformei-o em uma string para utilizar na URL que encontrei, concatenei as informa√ß√µes da URL com a vari√°vel para que em cada rodada do loop ela apresente as informa√ß√µes do UF selecionado, utilizei essa vari√°vel novamente nas bibliotecas citadas a cima s√≥ que dessa vez eu utilizei uma fun√ß√£o do JSON para ler a pagina que est√° no formato JSON, fiz outro loop para mostrar as informa√ß√µes solicitadas com alguns par√¢metros e encerrei o c√≥digo.</p>

</br>
</br>
<h4 align="center"> 
	üöß  Em constru√ß√£o...  üöß
</h4>

### Conquistas do projeto

- [x] Busca de informa√ß√µes no site.
- [x] Busca de todas UFs no site.
- [x] Busca da faixa de CEP de todos UFs.
- [ ] Colocar os dados em JSON.
</br>
</br>

Feito por Alyson Vieira üöÄ Entre em contato!!


[![Linkedin Badge](https://img.shields.io/badge/-Alyson-blue?style=flat-square&logo=Linkedin&logoColor=white&link=https://www.linkedin.com/in/alyson-mendon%C3%A7a-vieira-330551181/)](https://www.linkedin.com/in/alyson-mendon%C3%A7a-vieira-330551181/) 
[![Gmail Badge](https://img.shields.io/badge/-alysonvieira88@gmail.com-c14438?style=flat-square&logo=Gmail&logoColor=white&link=mailto:alysonvieira88@gmail.com)](mailto:alysonvieira88@gmail.com)
